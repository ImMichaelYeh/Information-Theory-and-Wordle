{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Information Theory and the Game Wordle (Part 1 of 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Goal of this lecture (Part 1 of 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This lecture will be split up into 2 parts. This first part will introduce the game wordle and the basic concepts of Information Theory that we will use. All the code written in this part will be in Julia. The 2nd part of this lecture will take our knowledge of Information Theory and combine it with the game Wordle to create an algorithm that would give us an optimal guess of words given the current information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## What is Wordle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you don't already know what the game Wordle is, you might be living under a rock. However, if that is true, you don't have to worry. That is because Wordle is a simple word game that operates off of a couple of rules.\n",
    "\n",
    "In this game, you'll have 6 guesses to find the hidden 5 letter word. For every letter of each guess, you will be told either:\n",
    "\n",
    "1. The letter does not exist in the word, marked with a gray box\n",
    "2. The letter exists in the word but is not in the right spot, marked with a yellow box\n",
    "3. The letter exists in the word and is in the right spot, marked with a green box\n",
    "\n",
    "**Here is an example:**\n",
    "Our first guess was \"CRATE\". Since the letters \"CRAT\" are in gray boxes, we know that none of those letters exist in this word. However, the last E is in a green box! So we know we got one! \n",
    "\n",
    "Our next guess is \"DRIED\".  Since the first D is now in a green box, we know the word begins with a D! Since there is another D in a yellow box, we know that there is at least another D somewhere in the word! \n",
    "\n",
    "\n",
    "\n",
    "Our final guess is the word \"DODGE\", which shows up in all green which means that we got the word in just 3 guesses!\\\n",
    "![Alt text](wordleExample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## What is our goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The goal of the game Wordle is to find the correct word within 6 guesses. However, for most players, we enjoy finding the word in the least amount of guesses possible! So, we want to be able to create an algorithm that would help us achieve this!\n",
    "\n",
    "\n",
    "One thing that we could try to do is to remove as many possibilities per guess as possible! In a simple guessing game, like trying to guess a number between 1 and 100 and being told if we are high or low! We can see that the least optimal way of guessing would be in order. For example, if the number is 75, then it would take 75 guesses to get the right answer! The optimal way would be to cut the numbers in half each time! Watch how this works:\n",
    "1. 50 (low, so well go into the middle of the higher interval)\n",
    "2. 75 (correct!)\n",
    "We were able to reduce our guess from 75 to just 2 using this algorithm! In fact, using this algorithm, the highest amount of guesses required would be $\\log_2(n)$ where n is the number of possible guesses. So that would mean that most amount of guesses for our number game is just 7!\n",
    "\n",
    "This is actually the equivalent of a binary search on a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: \n",
      "50\n",
      "25\n",
      "12\n",
      "6\n",
      "3\n",
      "1\n",
      "2\n",
      "\n",
      "8: \n",
      "50\n",
      "25\n",
      "12\n",
      "6\n",
      "9\n",
      "7\n",
      "8\n",
      "\n",
      "18: \n",
      "50\n",
      "25\n",
      "12\n",
      "18\n",
      "\n",
      "32: \n",
      "50\n",
      "25\n",
      "37\n",
      "31\n",
      "34\n",
      "32\n",
      "\n",
      "50: \n",
      "50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recursive example of this binary search\n",
    "function numberGuesser(rangeStart, rangeEnd, target)\n",
    "    if rangeStart > rangeEnd\n",
    "        return\n",
    "    end\n",
    "        \n",
    "    currentGuess = div((rangeStart + rangeEnd), 2) # Sets currentGuess to middle of the range\n",
    "    println(currentGuess)\n",
    "        \n",
    "    if currentGuess == target\n",
    "        return\n",
    "    elseif currentGuess > target\n",
    "        numberGuesser(rangeStart, currentGuess - 1, target)\n",
    "    else\n",
    "        numberGuesser(currentGuess + 1, rangeEnd, target)\n",
    "    end\n",
    "end\n",
    "\n",
    "for i in 1:5\n",
    "    println(string(2*i^2, \": \"))\n",
    "    numberGuesser(1, 100, 2*i^2)\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is great, but we can't exactly do this with Wordle. With our brains, we could usually guess things that would give us more information, but it is hard to think of what guesses would cut the amount of possible guesses down the most would be!\n",
    "\n",
    "\n",
    "Here is where Information Theory will come in handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Basics of Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In Information Theory, the unit of information used is called **the bit**. The amount of bits is usually represented with the letter I (for information) and can be solved with this equation $I = -\\log_2(p)$ where p how much smaller the space of possibilities becomes. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12972"
      ]
     },
     "execution_count": 2,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Julia file includes all the words that Wordle will accept as a guess, as well as all the possible answers.\n",
    "include(\"words.jl\") # I stole this information straight from the Wordle source code. \n",
    "\n",
    "length(words) + length(answers) # The words and answers are disjoint but you can type all of them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.991496463421989"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-log(670/10657)/log(2) # Number of bits of information from our example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are 12972 possible guesses that Wordle will accept. In reality, there are less words that it would use as answers, but let's ignore that. Now, let's say that the word CRATE cuts the number of guesses down from 12972 to just 810, then the amount of guesses have been cut down by a factor of almost 16! That means that amount of information that the word CRATE gives us is about $I = -\\log_2(1/16) = 4$! By finding the word for each guess that gives us the most amount of information or bits, we can reduce the number of possible guesses by as much as possible per guess!\n",
    "\n",
    "So how can we find which word would give us the most amount of information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Entropy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is a way for us to calculate the expected information that a word could give us! This function looks like this $E(w) = \\displaystyle\\sum_{x}-p(x)\\log_2(p(x))$. This is called the **Entropy Function**.\\\n",
    "Here, $w$ is the word that we are guessing. $x$ is one of the possible results that could appear on the screen, and $p(x)$ is the probability of each of those results.\n",
    "\n",
    "For example, if the word is \"CRATE\", the first x could be the result where all letters are gray. Then, $p(x$) is the probability of getting that result, and $-log_2(x)$ is the amount of information of that result. When we take the sum, we get the expected information of each guess.\n",
    "\n",
    "If we had a uniform distribution of possibilities, the Entropy function would be equal to $\\log_2(3^5)$ since there are $3^5$ equally likely outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.924812503605781"
      ]
     },
     "execution_count": 3,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(3^5)/log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The result of that is about 8. Which means that, at most, we would be able to cut our set down in half about 8 times! So there is a strict upperbound for our expected entropy value. However, since the probability of each outcome i not uniform, we can expect our entropy values to be lower than that for all of our guesses.\n",
    "\n",
    "So now, we want to find the word with the highest entropy, or the highest expected information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion for part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that you understand how the game Wordle works, and the basics of Information Theory, we can now write a program that can find us the optimal guess!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7",
   "env": {
    "JULIA_DEPOT_PATH": "/home/user/.julia/:/ext/julia/depot/",
    "JULIA_PROJECT": "/home/user/.julia/environment/v1.7"
   },
   "language": "julia",
   "metadata": {
    "cocalc": {
     "description": "The Julia Programming Language",
     "priority": 10,
     "url": "https://julialang.org/"
    }
   },
   "name": "julia-1.7",
   "resource_dir": "/ext/jupyter/kernels/julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}